<?xml version="1.0"?>
<launch>

<!-- Emotion interactions node -->
    <include file="$(find infrastructure)/launch/initiate_facial.launch"/>
<!-- Gaze_pose launch -->
    <include file="$(find infrastructure)/launch/gaze_pose.launch"/>
<!-- Speech_to_text launch -->
    <include file="$(find infrastructure)/launch/speech_to_text.launch"/>
<!-- Text_to_speech launch -->
    <include file="$(find infrastructure)/launch/text_to_speech.launch"/>
<!-- Speech_emotion_analysis launch-->
    <include file="$(find infrastructure)/launch/speech_emotion_analysis.launch"/>

<!-- Controlling the motors -->
    <node pkg="infrastructure" type="controller.py" name="motors_controller" output="screen"/>
    


<!-- Bridging between ROS and HTML interface node -->
    <include file="$(find rosbridge_server)/launch/rosbridge_websocket.launch">
        <arg name="unregister_timeout" value="100"/> <!-- 100 seconds -->
    </include>

<!-- Changing rosbridge node's topic name from default to "web_interface" -->
    <remap from="rosbridge_websocket" to="web_interface"/>

<!-- Streaming a video from the ROS server to the client -->
    <include file="$(find video_stream_opencv)/launch/camera.launch">
        <arg name="video_stream_provider" value="0" /> <!-- 0 for the default camera -->
        <arg name="visualize" value="false" /> <!-- true to visualize the video, meaning that the video will be displayed on the server -->
    </include>


</launch>